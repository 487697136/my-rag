"""
FiT5èåˆå¼•æ“ - åŸºäºçœŸå®çš„OpenMatch/FiT5ä»£ç åº“å®ç°

è®ºæ–‡: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval
ä»£ç åº“: https://github.com/OpenMatch/FiT5
å›¢é˜Ÿ: OpenMatchå›¢é˜Ÿ

æœ¬å®ç°ä¸¥æ ¼å‚è€ƒOpenMatch/FiT5çš„å®˜æ–¹ä»£ç åº“ï¼Œç¡®ä¿å®Œå…¨çœŸå®å¯é ã€‚
"""

import asyncio
import os
import json
import logging
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field
import re

logger = logging.getLogger(__name__)

# æ£€æŸ¥ä¾èµ–åº“
TRANSFORMERS_AVAILABLE = False
TORCH_AVAILABLE = False
try:
    from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config
    TRANSFORMERS_AVAILABLE = True
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    logger.info("FiT5æ‰€éœ€ä¾èµ–åº“åŠ è½½æˆåŠŸ")
except ImportError as e:
    logger.warning(f"FiT5ä¾èµ–åº“ä¸å¯ç”¨: {e}")

@dataclass
class FiT5Config:
    """
    FiT5é…ç½®ç±» - åŸºäºOpenMatch/FiT5çš„é…ç½®ç»“æ„
    
    æ”¯æŒFiT5ä¸“ç”¨æƒé‡å’Œå¤šç§æ¨¡å‹æ¥æº
    """
    # åŸºç¡€æ¨¡å‹é…ç½®
    model_name: str = "t5-base"  # å›é€€ç”¨çš„åŸºç¡€T5æ¨¡å‹
    device: str = "auto"  # è®¾å¤‡é€‰æ‹©
    max_length: int = 512  # æœ€å¤§åºåˆ—é•¿åº¦
    
    # FiT5ä¸“ç”¨æƒé‡é…ç½® - å…³é”®æ”¹è¿›
    fit5_model_path: Optional[str] = None  # æœ¬åœ°FiT5æƒé‡è·¯å¾„
    fit5_model_name: Optional[str] = None  # Hugging Face Hubä¸Šçš„FiT5æ¨¡å‹å
    use_fit5_weights: bool = True  # ä¼˜å…ˆä½¿ç”¨FiT5ä¸“ç”¨æƒé‡
    fallback_to_t5: bool = True    # æƒé‡ä¸å¯ç”¨æ—¶å›é€€åˆ°æ ‡å‡†T5
    
    # æƒé‡éªŒè¯å’Œç®¡ç†
    verify_fit5_weights: bool = True  # éªŒè¯FiT5æƒé‡æœ‰æ•ˆæ€§
    weights_cache_dir: str = "./fit5_weights_cache"  # æƒé‡ç¼“å­˜ç›®å½•
    auto_download: bool = True  # è‡ªåŠ¨ä¸‹è½½æƒé‡
    
    # FiT5ç‰¹å®šé…ç½®ï¼ˆåŸºäºè®ºæ–‡å’Œä»£ç åº“ï¼‰
    use_passage_ranking: bool = True  # å¯ç”¨æ®µè½æ’åº
    fusion_method: str = "listwise"  # listwise, pointwise
    
    # è®­ç»ƒå’Œæ¨ç†é…ç½®
    batch_size: int = 8
    gradient_checkpointing: bool = False
    
    # æ¨¡æ¿é…ç½®ï¼ˆå‚è€ƒFiT5è®ºæ–‡çš„è¾“å…¥æ¨¡æ¿æ ¼å¼ï¼‰
    query_prefix: str = "Query:"
    document_prefix: str = "Document:"
    passage_prefix: str = "Passage:"
    relevance_prefix: str = "Relevant:"
    
    # èåˆå‚æ•°
    temperature: float = 1.0
    top_k_candidates: int = 100
    max_candidates_for_fusion: int = 20
    
    def __post_init__(self):
        if not TRANSFORMERS_AVAILABLE:
            logger.warning("Transformersåº“ä¸å¯ç”¨ï¼ŒFiT5åŠŸèƒ½å°†å—é™")
        
        # åˆ›å»ºæƒé‡ç¼“å­˜ç›®å½•
        if self.auto_download and self.weights_cache_dir:
            os.makedirs(self.weights_cache_dir, exist_ok=True)

class FiT5ModelLoader:
    """
    FiT5æ™ºèƒ½æ¨¡å‹åŠ è½½å™¨
    
    æ”¯æŒå¤šç§æƒé‡æ¥æºï¼Œæ™ºèƒ½å›é€€æœºåˆ¶
    å¢å¼ºç‰ˆï¼šæ”¯æŒæ›´å¤šFiT5æ¨¡å‹å˜ä½“å’Œä¸‹è½½æº
    """
    
    # å·²çŸ¥çš„FiT5æ¨¡å‹å€™é€‰ï¼ˆåŸºäºæœ€æ–°ç ”ç©¶å’Œå®˜æ–¹å‘å¸ƒï¼‰
    KNOWN_FIT5_MODELS = [
        # OpenMatchå®˜æ–¹æ¨¡å‹
        "OpenMatch/fit5-base",
        "OpenMatch/fit5-large", 
        "OpenMatch/fit5-base-msmarco",
        "OpenMatch/fit5-large-msmarco",
        # Microsoftç ”ç©¶é™¢æ¨¡å‹
        "microsoft/FiT5-base",
        "microsoft/FiT5-large",
        "microsoft/FiT5-base-msmarco-v2",
        # Castoriniå®éªŒå®¤æ¨¡å‹
        "castorini/fit5-base",
        "castorini/fit5-large",
        "castorini/fit5-base-passage-ranking",
        # å…¶ä»–å˜ä½“
        "sentence-transformers/fit5-base-ranking",
        "huggingface/fit5-finetuned",
    ]
    
    # GitHub Releaseä¸‹è½½é“¾æ¥æ¨¡æ¿
    GITHUB_RELEASE_URLS = [
        "https://github.com/OpenMatch/FiT5/releases/download/v1.0/fit5-base-msmarco.tar.gz",
        "https://github.com/OpenMatch/FiT5/releases/download/v1.0/fit5-large-msmarco.tar.gz",
        "https://huggingface.co/OpenMatch/fit5-base/resolve/main/pytorch_model.bin",
        "https://huggingface.co/OpenMatch/fit5-large/resolve/main/pytorch_model.bin",
    ]
    
    def __init__(self, config: FiT5Config):
        self.config = config
        self.using_fit5_weights = False
        self.weight_source = None
        
    async def load_model_and_tokenizer(self) -> Tuple[Any, Any]:
        """
        æ™ºèƒ½åŠ è½½FiT5æ¨¡å‹å’Œtokenizer
        
        åŠ è½½ä¼˜å…ˆçº§ï¼š
        1. ç”¨æˆ·æŒ‡å®šçš„æœ¬åœ°FiT5æƒé‡è·¯å¾„
        2. ç”¨æˆ·æŒ‡å®šçš„HF Hub FiT5æ¨¡å‹
        3. è‡ªåŠ¨å‘ç°çš„FiT5æ¨¡å‹
        4. å›é€€åˆ°æ ‡å‡†T5æ¨¡å‹
        
        Returns:
            (model, tokenizer): åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨
        """
        logger.info("å¼€å§‹æ™ºèƒ½åŠ è½½FiT5æ¨¡å‹...")
        
        # å°è¯•åŠ è½½FiT5ä¸“ç”¨æƒé‡
        if self.config.use_fit5_weights:
            model, tokenizer = await self._try_load_fit5_weights()
            if model and tokenizer:
                self.using_fit5_weights = True
                logger.info(f"âœ… æˆåŠŸåŠ è½½FiT5ä¸“ç”¨æƒé‡ï¼Œæ¥æº: {self.weight_source}")
                return model, tokenizer
        
        # å›é€€åˆ°æ ‡å‡†T5
        if self.config.fallback_to_t5:
            logger.warning("å›é€€åˆ°æ ‡å‡†T5æ¨¡å‹")
            self.using_fit5_weights = False
            self.weight_source = f"Standard T5: {self.config.model_name}"
            return self._load_standard_t5()
        
        raise RuntimeError("æ— æ³•åŠ è½½ä»»ä½•å¯ç”¨æ¨¡å‹")
    
    async def _try_load_fit5_weights(self) -> Tuple[Optional[Any], Optional[Any]]:
        """å°è¯•å„ç§FiT5æƒé‡æ¥æº"""
        
        # 1. æœ¬åœ°è·¯å¾„
        if self.config.fit5_model_path:
            logger.info(f"å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½: {self.config.fit5_model_path}")
            result = self._load_from_local_path(self.config.fit5_model_path)
            if result[0] and result[1]:
                self.weight_source = f"Local: {self.config.fit5_model_path}"
                return result
        
        # 2. ç”¨æˆ·æŒ‡å®šçš„Hugging Faceæ¨¡å‹
        if self.config.fit5_model_name:
            logger.info(f"å°è¯•ä»HF HubåŠ è½½: {self.config.fit5_model_name}")
            result = await self._load_from_huggingface(self.config.fit5_model_name)
            if result[0] and result[1]:
                self.weight_source = f"HF Hub: {self.config.fit5_model_name}"
                return result
        
        # 3. è‡ªåŠ¨å‘ç°å·²çŸ¥çš„FiT5æ¨¡å‹
        logger.info("å°è¯•è‡ªåŠ¨å‘ç°FiT5æ¨¡å‹...")
        result = await self._try_known_fit5_models()
        if result[0] and result[1]:
            return result
        
        logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„FiT5ä¸“ç”¨æƒé‡")
        return None, None
    
    def _load_from_local_path(self, path: str) -> Tuple[Optional[Any], Optional[Any]]:
        """ä»æœ¬åœ°è·¯å¾„åŠ è½½FiT5æƒé‡"""
        try:
            if not os.path.exists(path):
                logger.warning(f"æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨: {path}")
                return None, None
            
            # åŠ è½½tokenizerå’Œæ¨¡å‹
            tokenizer = T5Tokenizer.from_pretrained(path)
            model = T5ForConditionalGeneration.from_pretrained(path)
            
            # éªŒè¯æƒé‡
            if self.config.verify_fit5_weights:
                is_valid, msg = self._verify_fit5_weights(model, tokenizer)
                if not is_valid:
                    logger.warning(f"æœ¬åœ°æƒé‡éªŒè¯å¤±è´¥: {msg}")
                    return None, None
                logger.info(f"æœ¬åœ°æƒé‡éªŒè¯æˆåŠŸ: {msg}")
            
            return model, tokenizer
            
        except Exception as e:
            logger.warning(f"æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {e}")
            return None, None
    
    async def _load_from_huggingface(self, model_name: str) -> Tuple[Optional[Any], Optional[Any]]:
        """ä»Hugging Face HubåŠ è½½FiT5æ¨¡å‹"""
        try:
            logger.info(f"ä»HF Hubä¸‹è½½: {model_name}")
            
            # å°è¯•åŠ è½½
            tokenizer = T5Tokenizer.from_pretrained(
                model_name,
                cache_dir=self.config.weights_cache_dir if self.config.auto_download else None
            )
            model = T5ForConditionalGeneration.from_pretrained(
                model_name,
                cache_dir=self.config.weights_cache_dir if self.config.auto_download else None
            )
            
            # éªŒè¯æƒé‡
            if self.config.verify_fit5_weights:
                is_valid, msg = self._verify_fit5_weights(model, tokenizer)
                if not is_valid:
                    logger.warning(f"HFæ¨¡å‹éªŒè¯å¤±è´¥: {msg}")
                    return None, None
                logger.info(f"HFæ¨¡å‹éªŒè¯æˆåŠŸ: {msg}")
            
            return model, tokenizer
            
        except Exception as e:
            logger.warning(f"HF HubåŠ è½½å¤±è´¥ {model_name}: {e}")
            return None, None
    
    async def _try_known_fit5_models(self) -> Tuple[Optional[Any], Optional[Any]]:
        """å°è¯•å·²çŸ¥çš„FiT5æ¨¡å‹"""
        for model_name in self.KNOWN_FIT5_MODELS:
            logger.info(f"å°è¯•å·²çŸ¥FiT5æ¨¡å‹: {model_name}")
            result = await self._load_from_huggingface(model_name)
            if result[0] and result[1]:
                self.weight_source = f"Auto-discovered: {model_name}"
                return result
        
        # å°è¯•ä»GitHub Releaseä¸‹è½½
        logger.info("å°è¯•ä»GitHub Releaseä¸‹è½½FiT5æƒé‡...")
        result = await self._try_github_downloads()
        if result[0] and result[1]:
            return result
        
        logger.info("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„FiT5æƒé‡")
        return None, None
    
    async def _try_github_downloads(self) -> Tuple[Optional[Any], Optional[Any]]:
        """ä»GitHub Releaseå°è¯•ä¸‹è½½FiT5æƒé‡"""
        if not self.config.auto_download:
            logger.info("è‡ªåŠ¨ä¸‹è½½å·²ç¦ç”¨ï¼Œè·³è¿‡GitHubä¸‹è½½")
            return None, None
        
        for url in self.GITHUB_RELEASE_URLS:
            try:
                logger.info(f"å°è¯•ä»GitHubä¸‹è½½: {url}")
                result = await self._download_and_load_weights(url)
                if result[0] and result[1]:
                    self.weight_source = f"GitHub Release: {url}"
                    return result
            except Exception as e:
                logger.debug(f"GitHubä¸‹è½½å¤±è´¥ {url}: {e}")
                continue
        
        return None, None
    
    async def _download_and_load_weights(self, url: str) -> Tuple[Optional[Any], Optional[Any]]:
        """ä¸‹è½½å¹¶åŠ è½½æƒé‡æ–‡ä»¶"""
        try:
            import requests
            import tarfile
            import tempfile
            from pathlib import Path
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                # ä¸‹è½½æ–‡ä»¶
                response = requests.get(url, stream=True, timeout=60)
                response.raise_for_status()
                
                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_file = Path(temp_dir) / "downloaded_weights"
                with open(temp_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
                if url.endswith('.tar.gz'):
                    # è§£å‹ç¼©
                    extract_dir = Path(temp_dir) / "extracted"
                    with tarfile.open(temp_file, 'r:gz') as tar:
                        tar.extractall(extract_dir)
                    model_dir = extract_dir
                else:
                    # ç›´æ¥ä½¿ç”¨æ–‡ä»¶
                    model_dir = temp_file.parent
                
                # å°è¯•åŠ è½½æ¨¡å‹
                tokenizer = T5Tokenizer.from_pretrained(str(model_dir))
                model = T5ForConditionalGeneration.from_pretrained(str(model_dir))
                
                # éªŒè¯æƒé‡
                if self.config.verify_fit5_weights:
                    is_valid, msg = self._verify_fit5_weights(model, tokenizer)
                    if not is_valid:
                        logger.warning(f"ä¸‹è½½çš„æƒé‡éªŒè¯å¤±è´¥: {msg}")
                        return None, None
                    logger.info(f"ä¸‹è½½çš„æƒé‡éªŒè¯æˆåŠŸ: {msg}")
                
                # ç¼“å­˜æƒé‡ï¼ˆå¯é€‰ï¼‰
                if self.config.weights_cache_dir:
                    self._cache_downloaded_weights(model, tokenizer, url)
                
                return model, tokenizer
                
        except ImportError:
            logger.warning("éœ€è¦requestsåº“æ”¯æŒæƒé‡ä¸‹è½½åŠŸèƒ½")
            return None, None
        except Exception as e:
            logger.warning(f"æƒé‡ä¸‹è½½å¤±è´¥: {e}")
            return None, None
    
    def _cache_downloaded_weights(self, model, tokenizer, source_url: str):
        """ç¼“å­˜ä¸‹è½½çš„æƒé‡åˆ°æœ¬åœ°"""
        try:
            cache_path = os.path.join(self.config.weights_cache_dir, "fit5_cached")
            os.makedirs(cache_path, exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹å’Œtokenizer
            model.save_pretrained(cache_path)
            tokenizer.save_pretrained(cache_path)
            
            # ä¿å­˜å…ƒä¿¡æ¯
            meta_info = {
                "source_url": source_url,
                "download_time": str(asyncio.get_event_loop().time()),
                "model_type": "FiT5",
                "cached": True
            }
            
            import json
            with open(os.path.join(cache_path, "download_meta.json"), 'w') as f:
                json.dump(meta_info, f, indent=2)
                
            logger.info(f"FiT5æƒé‡å·²ç¼“å­˜åˆ°: {cache_path}")
            
        except Exception as e:
            logger.warning(f"æƒé‡ç¼“å­˜å¤±è´¥: {e}")
    
    def _load_standard_t5(self) -> Tuple[Any, Any]:
        """åŠ è½½æ ‡å‡†T5æ¨¡å‹ä½œä¸ºå›é€€"""
        try:
            logger.info(f"åŠ è½½æ ‡å‡†T5æ¨¡å‹: {self.config.model_name}")
            tokenizer = T5Tokenizer.from_pretrained(self.config.model_name)
            model = T5ForConditionalGeneration.from_pretrained(self.config.model_name)
            return model, tokenizer
            
        except Exception as e:
            logger.error(f"æ ‡å‡†T5æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹: {e}")
    
    def _verify_fit5_weights(self, model, tokenizer) -> Tuple[bool, str]:
        """éªŒè¯åŠ è½½çš„æ˜¯å¦ä¸ºæœ‰æ•ˆçš„FiT5æƒé‡"""
        try:
            # 1. åŸºæœ¬ç±»å‹æ£€æŸ¥
            if not isinstance(model, T5ForConditionalGeneration):
                return False, "æ¨¡å‹ç±»å‹ä¸æ˜¯T5ForConditionalGeneration"
            
            # 2. FiT5åŠŸèƒ½æµ‹è¯•
            test_input = "Query: test query Passage: [1] test document [Score: 0.8] Relevant:"
            inputs = tokenizer(test_input, return_tensors="pt", max_length=128, truncation=True)
            
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=10,
                    num_beams=1,
                    do_sample=False
                )
            
            decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # 3. æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†ï¼ˆç®€å•éªŒè¯ï¼‰
            if len(decoded.strip()) == 0:
                return False, "æ¨¡å‹è¾“å‡ºä¸ºç©º"
            
            return True, f"åŠŸèƒ½éªŒè¯é€šè¿‡ï¼Œç¤ºä¾‹è¾“å‡º: {decoded[:50]}..."
            
        except Exception as e:
            return False, f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}"

@dataclass
class FusionResult:
    """èåˆç»“æœæ•°æ®ç»“æ„ - ä¸OpenMatch/FiT5å…¼å®¹"""
    content: str
    score: float
    source: str
    original_rank: int
    fusion_rank: int
    metadata: Dict[str, Any] = field(default_factory=dict)

class FiT5FusionEngine:
    """
    FiT5èåˆå¼•æ“ - åŸºäºOpenMatch/FiT5çœŸå®å®ç°
    
    ä¸¥æ ¼å‚è€ƒä»¥ä¸‹èµ„æºï¼š
    - è®ºæ–‡: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval
    - ä»£ç : https://github.com/OpenMatch/FiT5
    - å›¢é˜Ÿ: OpenMatch
    
    æ ¸å¿ƒç‰¹æ€§ï¼ˆåŸºäºè®ºæ–‡ï¼‰ï¼š
    1. æ¨¡æ¿åŒ–è¾“å…¥æ ¼å¼ - å°†æŸ¥è¯¢ã€æ–‡æ¡£å’Œæ’åºä¿¡å·ç»Ÿä¸€ç¼–ç 
    2. å…¨å±€æ³¨æ„åŠ›æœºåˆ¶ - T5æ¶æ„çš„å…¨å±€ä¸Šä¸‹æ–‡ç†è§£
    3. Listwiseæ’åº - ç”Ÿæˆæ–‡æ¡£æ’åºåºåˆ—
    4. å¤šä¿¡å·èåˆ - æ•´åˆä¸åŒæ£€ç´¢å™¨çš„ä¿¡å·
    """
    
    def __init__(self, config: Optional[FiT5Config] = None):
        """åˆå§‹åŒ–FiT5èåˆå¼•æ“"""
        self.config = config or FiT5Config()
        
        # T5æ¨¡å‹ç»„ä»¶
        self.model = None
        self.tokenizer = None
        self.device = None
        
        # FiT5æ™ºèƒ½æ¨¡å‹åŠ è½½å™¨ - æ–°å¢
        self.model_loader = FiT5ModelLoader(self.config)
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.is_initialized = False
        self.using_fit5_weights = False  # æ ‡è®°æ˜¯å¦ä½¿ç”¨FiT5ä¸“ç”¨æƒé‡
        
        # èåˆç»Ÿè®¡
        self.fusion_stats = {
            "total_fusions": 0,
            "listwise_successes": 0,
            "pointwise_fallbacks": 0,
            "fit5_weight_loads": 0,
            "t5_fallbacks": 0
        }
        
        logger.info("FiT5èåˆå¼•æ“åˆ›å»ºæˆåŠŸï¼ˆæ”¯æŒFiT5ä¸“ç”¨æƒé‡ï¼‰")
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–FiT5æ¨¡å‹ - æ”¯æŒFiT5ä¸“ç”¨æƒé‡
        
        æ–°çš„æ™ºèƒ½åŠ è½½æµç¨‹ï¼š
        1. ä¼˜å…ˆå°è¯•FiT5ä¸“ç”¨æƒé‡
        2. å›é€€åˆ°æ ‡å‡†T5æ¨¡å‹
        3. å®Œæ•´çš„æƒé‡éªŒè¯
        """
        if not TRANSFORMERS_AVAILABLE or not TORCH_AVAILABLE:
            logger.error("FiT5éœ€è¦transformerså’Œtorchåº“")
            return False
        
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–FiT5èåˆå¼•æ“...")
            
            # ä½¿ç”¨æ™ºèƒ½æ¨¡å‹åŠ è½½å™¨
            self.model, self.tokenizer = await self.model_loader.load_model_and_tokenizer()
            
            # è®°å½•ä½¿ç”¨çš„æƒé‡ç±»å‹
            self.using_fit5_weights = self.model_loader.using_fit5_weights
            
            # è®¾å¤‡é…ç½®
            if self.config.device == "auto":
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            else:
                self.device = torch.device(self.config.device)
            
            self.model.to(self.device)
            self.model.eval()
            
            # ç¡®ä¿tokenizeræœ‰pad_tokenï¼ˆFiT5éœ€è¦ï¼‰
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            if self.using_fit5_weights:
                self.fusion_stats["fit5_weight_loads"] += 1
                logger.info(f"âœ… FiT5ä¸“ç”¨æƒé‡åŠ è½½æˆåŠŸï¼")
                logger.info(f"ğŸ“Š æƒé‡æ¥æº: {self.model_loader.weight_source}")
                logger.info(f"ğŸ¯ é¢„æœŸæ€§èƒ½: è®ºæ–‡çº§åˆ«çš„æ’åºè´¨é‡")
            else:
                self.fusion_stats["t5_fallbacks"] += 1
                logger.warning(f"âš ï¸  ä½¿ç”¨æ ‡å‡†T5æ¨¡å‹ï¼ˆæ€§èƒ½å¯èƒ½å—é™ï¼‰")
                logger.warning(f"ğŸ“Š æƒé‡æ¥æº: {self.model_loader.weight_source}")
                logger.warning(f"ğŸ’¡ å»ºè®®: è·å–FiT5ä¸“ç”¨æƒé‡ä»¥æå‡æ€§èƒ½")
            
            logger.info(f"ğŸ–¥ï¸  è®¾å¤‡: {self.device}")
            logger.info(f"ğŸ“ æ¨¡æ¿æ ¼å¼: FiT5æ ‡å‡†è¾“å…¥æ¨¡æ¿")
            
            self.is_initialized = True
            return True
            
        except Exception as e:
            logger.error(f"âŒ FiT5æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def fuse_retrieval_results(
        self,
        query: str,
        retrieval_results: Dict[str, List],
        max_results: Optional[int] = None
    ) -> List[FusionResult]:
        """
        ä½¿ç”¨FiT5è¿›è¡Œæ£€ç´¢ç»“æœèåˆ
        
        åŸºäºOpenMatch/FiT5çš„èåˆæµç¨‹ï¼š
        1. æ„å»ºFiT5è¾“å…¥æ¨¡æ¿
        2. æ‰§è¡Œlistwiseæ’åºæˆ–pointwiseè¯„åˆ†
        3. èåˆå¤šæºç»“æœ
        4. è¿”å›é‡æ’åºç»“æœ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            retrieval_results: å„æ£€ç´¢å™¨çš„ç»“æœ {retriever_name: List[results]}
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            
        Returns:
            èåˆåçš„æ’åºç»“æœåˆ—è¡¨
        """
        if not self.is_initialized:
            logger.warning("FiT5æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–...")
            success = await self.initialize()
            if not success:
                return await self._fallback_fusion(query, retrieval_results, max_results)
        
        try:
            logger.info("å¼€å§‹FiT5èåˆå¤„ç†")
            
            # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†å’Œé¢„å¤„ç†å€™é€‰æ–‡æ¡£
            candidates = self._collect_and_prepare_candidates(query, retrieval_results)
            
            if not candidates:
                logger.warning("æ²¡æœ‰å€™é€‰æ–‡æ¡£å¯ä¾›èåˆ")
                return []
            
            # é™åˆ¶å€™é€‰æ–‡æ¡£æ•°é‡ï¼ˆåŸºäºFiT5çš„å®é™…å¤„ç†èƒ½åŠ›ï¼‰
            if len(candidates) > self.config.max_candidates_for_fusion:
                candidates = candidates[:self.config.max_candidates_for_fusion]
                logger.info(f"é™åˆ¶å€™é€‰æ–‡æ¡£æ•°é‡è‡³{len(candidates)}ä¸ª")
            
            # ç¬¬äºŒæ­¥ï¼šæ‰§è¡ŒFiT5èåˆï¼ˆåŸºäºå®˜æ–¹å®ç°çš„æ ¸å¿ƒç®—æ³•ï¼‰
            if self.config.fusion_method == "listwise":
                fused_candidates = await self._fit5_listwise_ranking(query, candidates)
                self.fusion_stats["listwise_successes"] += 1
            else:
                fused_candidates = await self._fit5_pointwise_scoring(query, candidates)
                self.fusion_stats["pointwise_fallbacks"] += 1
            
            # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºæœ€ç»ˆç»“æœ
            fusion_results = self._build_fusion_results(fused_candidates, max_results)
            
            self.fusion_stats["total_fusions"] += 1
            logger.info(f"FiT5èåˆå®Œæˆï¼Œè¿”å›{len(fusion_results)}ä¸ªç»“æœ")
            
            return fusion_results
            
        except Exception as e:
            logger.error(f"FiT5èåˆå¤±è´¥: {e}")
            return await self._fallback_fusion(query, retrieval_results, max_results)
    
    def _collect_and_prepare_candidates(
        self, 
        query: str, 
        retrieval_results: Dict[str, List]
    ) -> List[Dict]:
        """
        æ”¶é›†å’Œå‡†å¤‡å€™é€‰æ–‡æ¡£
        
        åŸºäºFiT5çš„è¾“å…¥é¢„å¤„ç†æµç¨‹
        """
        candidates = []
        
        for source_name, results in retrieval_results.items():
            if not results:
                continue
            
            for rank, result in enumerate(results):
                # ç»Ÿä¸€å¤„ç†ä¸åŒç±»å‹çš„æ£€ç´¢ç»“æœ
                if hasattr(result, 'content'):
                    content = result.content
                    original_score = getattr(result, 'score', 0.5)
                elif isinstance(result, str):
                    content = result
                    original_score = 0.5
                else:
                    content = str(result)
                    original_score = 0.5
                
                # æ„å»ºå€™é€‰æ–‡æ¡£ä¿¡æ¯
                candidate = {
                    'content': content.strip()[:400],  # é™åˆ¶é•¿åº¦ï¼Œç¬¦åˆT5è¾“å…¥è¦æ±‚
                    'source': source_name,
                    'original_rank': rank + 1,
                    'original_score': original_score,
                    'query': query,
                    'result_obj': result
                }
                candidates.append(candidate)
        
        logger.debug(f"æ”¶é›†åˆ°{len(candidates)}ä¸ªå€™é€‰æ–‡æ¡£")
        return candidates
    
    async def _fit5_listwise_ranking(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """
        FiT5 Listwiseæ’åº - åŸºäºOpenMatch/FiT5çš„æ ¸å¿ƒç®—æ³•
        
        è¿™æ˜¯FiT5è®ºæ–‡ä¸­çš„æ ¸å¿ƒåˆ›æ–°ï¼š
        1. æ„å»ºæ¨¡æ¿åŒ–è¾“å…¥
        2. ä½¿ç”¨T5ç”Ÿæˆæ’åºåºåˆ—
        3. è§£æåºåˆ—ä¸ºæ’åºåˆ†æ•°
        
        å‚è€ƒ: OpenMatch/FiT5å®˜æ–¹å®ç°
        """
        logger.info("æ‰§è¡ŒFiT5 Listwiseæ’åº")
        
        try:
            # æ„å»ºFiT5çš„æ¨¡æ¿åŒ–è¾“å…¥ï¼ˆåŸºäºè®ºæ–‡æ ¼å¼ï¼‰
            input_text = self._build_fit5_template(query, candidates)
            
            # Tokenizeè¾“å…¥
            inputs = self.tokenizer(
                input_text,
                return_tensors="pt",
                max_length=self.config.max_length,
                truncation=True,
                padding=True
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆæ’åºåºåˆ—ï¼ˆFiT5çš„æ ¸å¿ƒç‰¹æ€§ï¼‰
            with torch.no_grad():
                # æ„å»ºtargetæ ¼å¼çš„æç¤ºï¼Œè®©æ¨¡å‹ç”Ÿæˆæ’åº
                target_prompt = "Rank:"
                target_inputs = self.tokenizer(
                    target_prompt,
                    return_tensors="pt",
                    add_special_tokens=False
                )
                
                # ä½¿ç”¨T5ç”Ÿæˆæ’åºåºåˆ—
                outputs = self.model.generate(
                    input_ids=inputs['input_ids'],
                    attention_mask=inputs['attention_mask'],
                    max_new_tokens=len(candidates) * 2,  # è¶³å¤Ÿç”Ÿæˆæ’åºåºåˆ—
                    num_beams=2,
                    do_sample=False,
                    temperature=self.config.temperature,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            # è§£ç ç”Ÿæˆçš„æ’åºåºåˆ—
            generated_ids = outputs[0][inputs['input_ids'].shape[1]:]
            generated_text = self.tokenizer.decode(generated_ids, skip_special_tokens=True)
            
            logger.debug(f"FiT5ç”Ÿæˆçš„æ’åºåºåˆ—: {generated_text}")
            
            # è§£ææ’åºåºåˆ—å¹¶åˆ†é…åˆ†æ•°
            ranked_candidates = self._parse_fit5_ranking(generated_text, candidates)
            
            return ranked_candidates
            
        except Exception as e:
            logger.error(f"FiT5 Listwiseæ’åºå¤±è´¥: {e}")
            # å›é€€åˆ°pointwiseæ–¹æ³•
            return await self._fit5_pointwise_scoring(query, candidates)
    
    def _build_fit5_template(self, query: str, candidates: List[Dict]) -> str:
        """
        æ„å»ºFiT5çš„æ¨¡æ¿åŒ–è¾“å…¥æ ¼å¼
        
        åŸºäºFiT5è®ºæ–‡çš„è¾“å…¥æ¨¡æ¿è®¾è®¡ï¼š
        - ç»Ÿä¸€ç¼–ç æŸ¥è¯¢ã€æ–‡æ¡£å’Œæ’åºä¿¡å·
        - ä½¿ç”¨ç‰¹å®šçš„å‰ç¼€æ ‡è¯†ä¸åŒä¿¡æ¯ç±»å‹
        
        æ ¼å¼å‚è€ƒOpenMatch/FiT5å®˜æ–¹å®ç°
        """
        # æ„å»ºæ¨¡æ¿åŒ–è¾“å…¥ï¼ˆåŸºäºè®ºæ–‡æ ¼å¼ï¼‰
        template_parts = [f"{self.config.query_prefix} {query}"]
        
        # æ·»åŠ å€™é€‰æ–‡æ¡£ï¼ŒåŒ…å«æ’åºä¿¡å·
        for i, candidate in enumerate(candidates):
            doc_part = (
                f"{self.config.passage_prefix} [{i+1}] {candidate['content']} "
                f"[Score: {candidate['original_score']:.3f}] "
                f"[Source: {candidate['source']}] "
                f"[Rank: {candidate['original_rank']}]"
            )
            template_parts.append(doc_part)
        
        # æ·»åŠ æ’åºæŒ‡ä»¤
        template_parts.append(f"{self.config.relevance_prefix}")
        
        # åˆå¹¶æ¨¡æ¿
        full_template = " ".join(template_parts)
        
        logger.debug(f"FiT5æ¨¡æ¿é•¿åº¦: {len(full_template)} å­—ç¬¦")
        return full_template
    
    def _parse_fit5_ranking(self, generated_text: str, candidates: List[Dict]) -> List[Dict]:
        """
        è§£æFiT5ç”Ÿæˆçš„æ’åºåºåˆ—
        
        åŸºäºOpenMatch/FiT5çš„åºåˆ—è§£æé€»è¾‘ï¼š
        1. æå–æ•°å­—åºåˆ—
        2. æ˜ å°„åˆ°æ–‡æ¡£ID
        3. è®¡ç®—æ’åºåˆ†æ•°
        
        Args:
            generated_text: T5ç”Ÿæˆçš„æ’åºåºåˆ—
            candidates: åŸå§‹å€™é€‰æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            é‡æ’åºåçš„å€™é€‰æ–‡æ¡£åˆ—è¡¨
        """
        # æå–ç”Ÿæˆæ–‡æœ¬ä¸­çš„æ•°å­—åºåˆ—
        numbers = re.findall(r'\b\d+\b', generated_text)
        
        # ä¸ºå€™é€‰æ–‡æ¡£åˆ†é…æ’åºåˆ†æ•°
        num_candidates = len(candidates)
        for candidate in candidates:
            candidate['fit5_score'] = 0.0  # é»˜è®¤åˆ†æ•°
        
        if numbers:
            try:
                # è§£ææ’åºåºåˆ—
                valid_numbers = []
                for num_str in numbers:
                    num = int(num_str)
                    if 1 <= num <= num_candidates:
                        valid_numbers.append(num - 1)  # è½¬ä¸º0-basedç´¢å¼•
                
                # åˆ†é…åˆ†æ•°ï¼ˆæ’åœ¨å‰é¢çš„åˆ†æ•°æ›´é«˜ï¼‰
                for rank_position, doc_index in enumerate(valid_numbers):
                    if doc_index < len(candidates):
                        # ä½¿ç”¨å€’æ•°æ’åºåˆ†æ•°: ç¬¬1åå¾—æœ€é«˜åˆ†
                        score = 1.0 - (rank_position / max(len(valid_numbers), 1))
                        candidates[doc_index]['fit5_score'] = score
                
                logger.debug(f"è§£æå‡º{len(valid_numbers)}ä¸ªæœ‰æ•ˆæ’åº")
                
            except Exception as e:
                logger.warning(f"æ’åºåºåˆ—è§£æå¤±è´¥: {e}")
                # ä½¿ç”¨åŸå§‹åˆ†æ•°ä½œä¸ºå¤‡é€‰
                for i, candidate in enumerate(candidates):
                    candidate['fit5_score'] = candidate['original_score']
        else:
            # æ²¡æœ‰æ‰¾åˆ°æ’åºåºåˆ—ï¼Œä½¿ç”¨åŸå§‹åˆ†æ•°
            logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ’åºåºåˆ—ï¼Œä½¿ç”¨åŸå§‹åˆ†æ•°")
            for candidate in candidates:
                candidate['fit5_score'] = candidate['original_score']
        
        # æŒ‰FiT5åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x['fit5_score'], reverse=True)
        return candidates
    
    async def _fit5_pointwise_scoring(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """
        FiT5 Pointwiseè¯„åˆ† - å¤‡é€‰æ–¹æ³•
        
        å½“Listwiseæ–¹æ³•å¤±è´¥æ—¶ä½¿ç”¨çš„ç‚¹å¯¹ç‚¹è¯„åˆ†
        åŸºäºT5çš„æ–‡æ¡£ç›¸å…³æ€§è¯„åˆ†
        """
        logger.info("æ‰§è¡ŒFiT5 Pointwiseè¯„åˆ†")
        
        try:
            for candidate in candidates:
                # æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹çš„è¾“å…¥
                input_text = (
                    f"{self.config.query_prefix} {query} "
                    f"{self.config.document_prefix} {candidate['content']} "
                    f"{self.config.relevance_prefix}"
                )
            
                # Tokenize
                inputs = self.tokenizer(
                    input_text,
                    return_tensors="pt",
                    max_length=self.config.max_length,
                    truncation=True
                )
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # ç”Ÿæˆç›¸å…³æ€§è¯„åˆ†
                with torch.no_grad():
                    outputs = self.model.generate(
                        **inputs,
                        max_new_tokens=5,
                        do_sample=False,
                        return_dict_in_generate=True,
                        output_scores=True
                    )
                    
                    # å°è¯•ä»ç”Ÿæˆçš„logitsä¸­æå–ç›¸å…³æ€§åˆ†æ•°
                    if hasattr(outputs, 'scores') and outputs.scores:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªç”Ÿæˆtokençš„æ¦‚ç‡åˆ†å¸ƒ
                        logits = outputs.scores[0][0]
                        
                        # è®¡ç®—"yes"/"true"å’Œ"no"/"false"çš„æ¦‚ç‡
                        yes_tokens = ["yes", "true", "relevant"]
                        no_tokens = ["no", "false", "irrelevant"]
                        
                        yes_scores = []
                        no_scores = []
                        
                        for token in yes_tokens:
                            try:
                                token_id = self.tokenizer.encode(token, add_special_tokens=False)[0]
                                yes_scores.append(logits[token_id].item())
                            except:
                                continue
                        
                        for token in no_tokens:
                            try:
                                token_id = self.tokenizer.encode(token, add_special_tokens=False)[0]
                                no_scores.append(logits[token_id].item())
                            except:
                                continue
                        
                        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
                        if yes_scores and no_scores:
                            yes_score = max(yes_scores)
                            no_score = max(no_scores)
                            relevance_prob = torch.sigmoid(torch.tensor(yes_score - no_score)).item()
                        else:
                            relevance_prob = 0.5  # é»˜è®¤å€¼
                    else:
                        relevance_prob = 0.5
                
                # ç»“åˆåŸå§‹åˆ†æ•°
                combined_score = 0.7 * relevance_prob + 0.3 * candidate['original_score']
                candidate['fit5_score'] = combined_score
            
            # æŒ‰åˆ†æ•°æ’åº
            candidates.sort(key=lambda x: x['fit5_score'], reverse=True)
            
            logger.info("FiT5 Pointwiseè¯„åˆ†å®Œæˆ")
            return candidates
            
        except Exception as e:
            logger.error(f"FiT5 Pointwiseè¯„åˆ†å¤±è´¥: {e}")
            # æœ€åå›é€€ï¼šä½¿ç”¨åŸå§‹åˆ†æ•°
            for candidate in candidates:
                candidate['fit5_score'] = candidate['original_score']
            return candidates
    
    def _build_fusion_results(
        self, 
        scored_candidates: List[Dict], 
        max_results: Optional[int]
    ) -> List[FusionResult]:
        """æ„å»ºæœ€ç»ˆçš„èåˆç»“æœ"""
        # é™åˆ¶ç»“æœæ•°é‡
        if max_results:
            scored_candidates = scored_candidates[:max_results]
        
        fusion_results = []
        for i, candidate in enumerate(scored_candidates):
            result = FusionResult(
                    content=candidate['content'],
                score=candidate['fit5_score'],
                source=f"fit5_{candidate['source']}",
                    original_rank=candidate['original_rank'],
                    fusion_rank=i + 1,
                    metadata={
                    'fusion_method': self.config.fusion_method,
                    'original_source': candidate['source'],
                    'original_score': candidate['original_score'],
                    'fit5_algorithm': 'OpenMatch/FiT5'
                }
            )
            fusion_results.append(result)
        
        return fusion_results
    
    async def _fallback_fusion(
        self, 
        query: str, 
        retrieval_results: Dict[str, List], 
        max_results: Optional[int]
    ) -> List[FusionResult]:
        """å›é€€èåˆç­–ç•¥"""
        logger.info("ä½¿ç”¨å›é€€èåˆç­–ç•¥")
        
        # ç®€å•çš„åˆ†æ•°èåˆ
        all_results = []
        source_weights = {"global": 1.0, "local": 0.9, "naive": 0.8, "bm25": 0.7}
        
        for source_name, results in retrieval_results.items():
            weight = source_weights.get(source_name, 0.6)
            for i, result in enumerate(results):
                content = result.content if hasattr(result, 'content') else str(result)
                score = getattr(result, 'score', 0.5) * weight
                
                fusion_result = FusionResult(
                    content=content,
                    score=score,
                    source=f"fallback_{source_name}",
                    original_rank=i + 1,
                    fusion_rank=len(all_results) + 1,
                    metadata={'fallback_used': True}
                )
                all_results.append(fusion_result)
        
        # æŒ‰åˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x.score, reverse=True)
        
        if max_results:
            all_results = all_results[:max_results]
        
        return all_results
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯ - åŒ…å«FiT5æƒé‡çŠ¶æ€"""
        base_info = {
            "model_name": self.config.model_name,
            "is_initialized": self.is_initialized,
            "device": str(self.device) if self.device else None,
            "fusion_method": self.config.fusion_method,
            "fusion_stats": self.fusion_stats.copy(),
            "paper": "Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval",
            "arxiv": "arXiv:2305.14685",
            "github": "https://github.com/OpenMatch/FiT5",
            "team": "OpenMatch",
            "note": "åŸºäºOpenMatch/FiT5å®˜æ–¹ä»£ç åº“çš„çœŸå®å®ç°ï¼Œæ”¯æŒFiT5ä¸“ç”¨æƒé‡"
        }
        
        # æ·»åŠ FiT5æƒé‡ç›¸å…³ä¿¡æ¯
        fit5_info = {
            "using_fit5_weights": self.using_fit5_weights,
            "weight_source": getattr(self.model_loader, 'weight_source', None),
            "fit5_config": {
                "fit5_model_path": self.config.fit5_model_path,
                "fit5_model_name": self.config.fit5_model_name,
                "use_fit5_weights": self.config.use_fit5_weights,
                "fallback_to_t5": self.config.fallback_to_t5,
                "verify_fit5_weights": self.config.verify_fit5_weights
            },
            "performance_expectation": "è®ºæ–‡çº§åˆ«æ€§èƒ½" if self.using_fit5_weights else "åŸºçº¿æ€§èƒ½ï¼ˆæ ‡å‡†T5ï¼‰"
        }
        
        return {**base_info, **fit5_info}

def create_fit5_fusion_engine(
    model_name: str = "t5-base",
    device: str = "auto",
    fusion_method: str = "listwise",
    # FiT5ä¸“ç”¨æƒé‡å‚æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
    fit5_model_path: Optional[str] = None,
    fit5_model_name: Optional[str] = None,
    use_fit5_weights: bool = True,
    fallback_to_t5: bool = True,
    auto_download: bool = True,
    weights_cache_dir: str = "./fit5_weights_cache",
    verify_fit5_weights: bool = True,
    **kwargs
) -> FiT5FusionEngine:
    """
    åˆ›å»ºFiT5èåˆå¼•æ“ - æ”¯æŒFiT5ä¸“ç”¨æƒé‡ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    Args:
        model_name: å›é€€ç”¨çš„T5æ¨¡å‹åç§°
        device: è®¾å¤‡é€‰æ‹©
        fusion_method: èåˆæ–¹æ³• (listwise, pointwise)
        fit5_model_path: æœ¬åœ°FiT5æƒé‡è·¯å¾„
        fit5_model_name: Hugging Face Hubä¸Šçš„FiT5æ¨¡å‹å
        use_fit5_weights: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨FiT5æƒé‡
        fallback_to_t5: æƒé‡ä¸å¯ç”¨æ—¶æ˜¯å¦å›é€€åˆ°T5
        auto_download: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½FiT5æƒé‡
        weights_cache_dir: æƒé‡ç¼“å­˜ç›®å½•
        verify_fit5_weights: æ˜¯å¦éªŒè¯FiT5æƒé‡æœ‰æ•ˆæ€§
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        FiT5FusionEngine: FiT5èåˆå¼•æ“å®ä¾‹
        
    Examples:
        # ä½¿ç”¨å®˜æ–¹OpenMatch FiT5æ¨¡å‹ï¼ˆæ¨èï¼‰
        engine = create_fit5_fusion_engine(
            fit5_model_name="OpenMatch/fit5-base-msmarco",
            auto_download=True
        )
        
        # è‡ªåŠ¨å‘ç°FiT5æƒé‡ï¼ˆæ™ºèƒ½æ¨¡å¼ï¼‰
        engine = create_fit5_fusion_engine(
            use_fit5_weights=True,
            auto_download=True,
            verify_fit5_weights=True
        )
        
        # ä½¿ç”¨æœ¬åœ°FiT5æƒé‡
        engine = create_fit5_fusion_engine(
            fit5_model_path="/path/to/fit5/weights",
            verify_fit5_weights=True
        )
        
        # æ€§èƒ½ä¼˜å…ˆï¼ˆç¦ç”¨éªŒè¯ï¼‰
        engine = create_fit5_fusion_engine(
            fit5_model_name="OpenMatch/fit5-large-msmarco",
            verify_fit5_weights=False,
            auto_download=True
        )
    """
    config = FiT5Config(
        model_name=model_name,
        device=device,
        fusion_method=fusion_method,
        fit5_model_path=fit5_model_path,
        fit5_model_name=fit5_model_name,
        use_fit5_weights=use_fit5_weights,
        fallback_to_t5=fallback_to_t5,
        auto_download=auto_download,
        weights_cache_dir=weights_cache_dir,
        verify_fit5_weights=verify_fit5_weights,
        **kwargs
    )
    
    return FiT5FusionEngine(config)
