#!/usr/bin/env python3
"""
å®éªŒä¸€ï¼šæœ¬åœ°æ¨¡å‹ä¸‹è½½å’Œç®¡ç†è„šæœ¬

åŠŸèƒ½ï¼š
1. ä» Hugging Face ä¸‹è½½æŒ‡å®šæ¨¡å‹åˆ°æœ¬åœ°
2. æ”¯æŒæ–­ç‚¹ç»­ä¼ 
3. éªŒè¯æ¨¡å‹å®Œæ•´æ€§
4. ç®¡ç†æœ¬åœ°æ¨¡å‹å­˜å‚¨

è¿è¡Œæ–¹å¼ï¼š
    python scripts/00_download_models.py --models bert-base-cased roberta-large
    python scripts/00_download_models.py --all  # ä¸‹è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹
"""

import os
import sys
import json
import yaml
import argparse
import logging
import hashlib
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime

import torch
from transformers import (
    AutoTokenizer, AutoModel, AutoConfig,
    BertTokenizer, BertModel,
    RobertaTokenizer, RobertaModel
)
from huggingface_hub import snapshot_download, Repository
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))
experiment_root = Path(__file__).parent.parent
sys.path.insert(0, str(experiment_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(experiment_root / 'outputs' / 'logs' / 'model_download.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class LocalModelManager:
    """æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, experiment_root: Path):
        """
        Args:
            experiment_root: å®éªŒæ ¹ç›®å½•
        """
        self.experiment_root = Path(experiment_root)
        self.models_dir = self.experiment_root / 'models'
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¨¡å‹æ˜ å°„é…ç½®
        self.model_configs = {
            'bert-base-cased': {
                'hf_name': 'bert-base-cased',  # ä½¿ç”¨å®˜æ–¹ç¨³å®šä»“åº“ IDï¼Œé¿å… 404/æ— æƒé™
                'local_name': 'bert_base_cased',
                'type': 'bert',
                'hidden_size': 768
            },
            'roberta-large': {
                'hf_name': 'FacebookAI/roberta-large',  # ä½¿ç”¨æœ€æ–°çš„ç»„ç»‡è·¯å¾„
                'local_name': 'roberta_large',
                'type': 'roberta',
                'hidden_size': 1024
            }
        }
        
        # ä¸‹è½½è¿›åº¦è·Ÿè¸ªæ–‡ä»¶
        self.download_status_file = self.models_dir / 'download_status.json'
        self.download_status = self._load_download_status()
    
    def _load_download_status(self) -> Dict:
        """åŠ è½½ä¸‹è½½çŠ¶æ€"""
        if self.download_status_file.exists():
            try:
                with open(self.download_status_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½ä¸‹è½½çŠ¶æ€å¤±è´¥: {e}")
        
        return {
            'downloaded_models': {},
            'failed_downloads': [],
            'last_update': None
        }
    
    def _save_download_status(self):
        """ä¿å­˜ä¸‹è½½çŠ¶æ€"""
        self.download_status['last_update'] = datetime.now().isoformat()
        try:
            with open(self.download_status_file, 'w', encoding='utf-8') as f:
                json.dump(self.download_status, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜ä¸‹è½½çŠ¶æ€å¤±è´¥: {e}")
    
    def _calculate_directory_hash(self, directory: Path) -> str:
        """è®¡ç®—ç›®å½•çš„å“ˆå¸Œå€¼ï¼ˆç”¨äºéªŒè¯å®Œæ•´æ€§ï¼‰"""
        hash_md5 = hashlib.md5()
        for file_path in sorted(directory.rglob('*')):
            if file_path.is_file():
                try:
                    with open(file_path, 'rb') as f:
                        for chunk in iter(lambda: f.read(4096), b""):
                            hash_md5.update(chunk)
                except Exception:
                    continue
        return hash_md5.hexdigest()
    
    def is_model_downloaded(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
        if model_name not in self.model_configs:
            return False
        
        local_name = self.model_configs[model_name]['local_name']
        local_path = self.models_dir / local_name
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«å¿…è¦æ–‡ä»¶
        if not local_path.exists():
            return False
        
        required_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json', 'vocab.txt']
        for file_name in required_files:
            if not (local_path / file_name).exists():
                # æŸäº›æ¨¡å‹å¯èƒ½ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å
                continue
        
        # æ£€æŸ¥ä¸‹è½½çŠ¶æ€è®°å½•
        return local_name in self.download_status['downloaded_models']
    
    def download_model(self, model_name: str, force_redownload: bool = False) -> bool:
        """ä¸‹è½½å•ä¸ªæ¨¡å‹åˆ°æœ¬åœ°"""
        if model_name not in self.model_configs:
            logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            return False
        
        config = self.model_configs[model_name]
        local_name = config['local_name']
        hf_name = config['hf_name']
        local_path = self.models_dir / local_name
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½ï¼ˆé™¤éå¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰
        if not force_redownload and self.is_model_downloaded(model_name):
            logger.info(f"âœ… {model_name} å·²ä¸‹è½½åˆ° {local_path}")
            return True
        
        logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {model_name} åˆ° {local_path}")
        
        try:
            # åˆ›å»ºæœ¬åœ°ç›®å½•
            local_path.mkdir(parents=True, exist_ok=True)
            
            # è®¾ç½®ä¸‹è½½å‚æ•°
            download_kwargs = {
                'repo_id': hf_name,
                'local_dir': str(local_path),
                'resume_download': True,  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                'local_dir_use_symlinks': False,  # ä¸ä½¿ç”¨ç¬¦å·é“¾æ¥
            }
            
            # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
            logger.info(f"æ­£åœ¨ä» {hf_name} ä¸‹è½½...")
            
            # ä½¿ç”¨ snapshot_download ä¸‹è½½æ•´ä¸ªä»“åº“
            try:
                snapshot_download(**download_kwargs)
                logger.info(f"âœ… {model_name} ä¸‹è½½å®Œæˆ")
            except Exception as e:
                logger.error(f"ä½¿ç”¨ snapshot_download å¤±è´¥: {e}")
                logger.info("å°è¯•ä½¿ç”¨ transformers åº“ä¸‹è½½...")
                
                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ transformers åº“ä¸‹è½½
                self._download_with_transformers(hf_name, local_path, config['type'])
            
            # éªŒè¯ä¸‹è½½å®Œæ•´æ€§
            if self._verify_model_integrity(local_path, config['type']):
                # æ›´æ–°ä¸‹è½½çŠ¶æ€
                self.download_status['downloaded_models'][local_name] = {
                    'hf_name': hf_name,
                    'local_path': str(local_path),
                    'download_time': datetime.now().isoformat(),
                    'hash': self._calculate_directory_hash(local_path),
                    'model_type': config['type'],
                    'hidden_size': config['hidden_size']
                }
                self._save_download_status()
                
                logger.info(f"âœ… {model_name} ä¸‹è½½å¹¶éªŒè¯æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ {model_name} ä¸‹è½½åéªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ {model_name} ä¸‹è½½å¤±è´¥: {e}")
            
            # è®°å½•å¤±è´¥ä¿¡æ¯
            failure_info = {
                'model_name': model_name,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            self.download_status['failed_downloads'].append(failure_info)
            self._save_download_status()
            
            return False
    
    def _download_with_transformers(self, hf_name: str, local_path: Path, model_type: str):
        """ä½¿ç”¨ transformers åº“ä¸‹è½½æ¨¡å‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        logger.info(f"ä½¿ç”¨ transformers åº“ä¸‹è½½ {hf_name}...")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©åˆé€‚çš„ç±»
        if model_type == 'bert':
            tokenizer_class = BertTokenizer
            model_class = BertModel
        elif model_type == 'roberta':
            tokenizer_class = RobertaTokenizer
            model_class = RobertaModel
        else:
            tokenizer_class = AutoTokenizer
            model_class = AutoModel
        
        # ä¸‹è½½é…ç½®æ–‡ä»¶
        config = AutoConfig.from_pretrained(hf_name)
        config.save_pretrained(local_path)
        
        # ä¸‹è½½åˆ†è¯å™¨
        tokenizer = tokenizer_class.from_pretrained(hf_name)
        tokenizer.save_pretrained(local_path)
        
        # ä¸‹è½½æ¨¡å‹
        model = model_class.from_pretrained(hf_name)
        model.save_pretrained(local_path)
        
        logger.info(f"âœ… ä½¿ç”¨ transformers åº“ä¸‹è½½ {hf_name} å®Œæˆ")
    
    def _verify_model_integrity(self, local_path: Path, model_type: str) -> bool:
        """éªŒè¯æ¨¡å‹å®Œæ•´æ€§"""
        try:
            logger.info(f"éªŒè¯æ¨¡å‹å®Œæ•´æ€§: {local_path}")
            
            # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            config_file = local_path / 'config.json'
            if not config_file.exists():
                logger.error("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            # å°è¯•åŠ è½½é…ç½®
            config = AutoConfig.from_pretrained(str(local_path), local_files_only=True)
            
            # å°è¯•åŠ è½½åˆ†è¯å™¨
            tokenizer = AutoTokenizer.from_pretrained(str(local_path), local_files_only=True)
            
            # å°è¯•åŠ è½½æ¨¡å‹ï¼ˆä»…æ£€æŸ¥èƒ½å¦åŠ è½½ï¼Œä¸å®é™…åŠ è½½åˆ°å†…å­˜ï¼‰
            model = AutoModel.from_pretrained(
                str(local_path), 
                local_files_only=True,
                torch_dtype=torch.float32  # ä½¿ç”¨è¾ƒå°çš„æ•°æ®ç±»å‹ä»¥èŠ‚çœå†…å­˜
            )
            
            # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
            test_input = tokenizer("This is a test", return_tensors="pt", max_length=16, truncation=True)
            with torch.no_grad():
                output = model(**test_input)
            
            logger.info("âœ… æ¨¡å‹å®Œæ•´æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def get_local_model_path(self, model_name: str) -> Optional[Path]:
        """è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„"""
        if not self.is_model_downloaded(model_name):
            return None
        
        local_name = self.model_configs[model_name]['local_name']
        return self.models_dir / local_name
    
    def list_downloaded_models(self) -> Dict:
        """åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹"""
        return self.download_status['downloaded_models']
    
    def download_all_required_models(self, force_redownload: bool = False) -> Dict[str, bool]:
        """ä¸‹è½½æ‰€æœ‰å®éªŒæ‰€éœ€çš„æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰å®éªŒæ‰€éœ€çš„æ¨¡å‹...")
        
        results = {}
        total_models = len(self.model_configs)
        
        for i, model_name in enumerate(self.model_configs.keys(), 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"[{i}/{total_models}] å¤„ç†æ¨¡å‹: {model_name}")
            logger.info(f"{'='*60}")
            
            success = self.download_model(model_name, force_redownload)
            results[model_name] = success
            
            if success:
                logger.info(f"âœ… [{i}/{total_models}] {model_name} å¤„ç†æˆåŠŸ")
            else:
                logger.error(f"âŒ [{i}/{total_models}] {model_name} å¤„ç†å¤±è´¥")
        
        # è¾“å‡ºæ±‡æ€»æŠ¥å‘Š
        self._print_download_summary(results)
        
        return results
    
    def _print_download_summary(self, results: Dict[str, bool]):
        """æ‰“å°ä¸‹è½½æ±‡æ€»æŠ¥å‘Š"""
        successful = [model for model, success in results.items() if success]
        failed = [model for model, success in results.items() if not success]
        
        logger.info(f"\n{'='*70}")
        logger.info("ğŸ“Š æ¨¡å‹ä¸‹è½½æ±‡æ€»æŠ¥å‘Š")
        logger.info(f"{'='*70}")
        logger.info(f"âœ… æˆåŠŸä¸‹è½½: {len(successful)} ä¸ªæ¨¡å‹")
        for model in successful:
            local_path = self.get_local_model_path(model)
            logger.info(f"   â€¢ {model} â†’ {local_path}")
        
        if failed:
            logger.info(f"\nâŒ ä¸‹è½½å¤±è´¥: {len(failed)} ä¸ªæ¨¡å‹")
            for model in failed:
                logger.info(f"   â€¢ {model}")
        
        logger.info(f"\nğŸ“ æ‰€æœ‰æ¨¡å‹å­˜å‚¨åœ¨: {self.models_dir}")
        
        # è®¡ç®—æ€»å ç”¨ç©ºé—´
        total_size = self._calculate_total_size()
        logger.info(f"ğŸ’¾ æ€»å ç”¨ç©ºé—´: {total_size}")
    
    def _calculate_total_size(self) -> str:
        """è®¡ç®—å·²ä¸‹è½½æ¨¡å‹çš„æ€»å¤§å°"""
        total_bytes = 0
        for model_path in self.models_dir.iterdir():
            if model_path.is_dir():
                for file_path in model_path.rglob('*'):
                    if file_path.is_file():
                        try:
                            total_bytes += file_path.stat().st_size
                        except Exception:
                            continue
        
        # è½¬æ¢ä¸ºäººç±»å¯è¯»çš„æ ¼å¼
        for unit in ['B', 'KB', 'MB', 'GB']:
            if total_bytes < 1024.0:
                return f"{total_bytes:.1f} {unit}"
            total_bytes /= 1024.0
        return f"{total_bytes:.1f} TB"
    
    def clean_failed_downloads(self):
        """æ¸…ç†å¤±è´¥çš„ä¸‹è½½"""
        logger.info("ğŸ§¹ æ¸…ç†å¤±è´¥çš„ä¸‹è½½...")
        
        for model_name in self.model_configs:
            local_name = self.model_configs[model_name]['local_name']
            local_path = self.models_dir / local_name
            
            if local_path.exists() and not self.is_model_downloaded(model_name):
                try:
                    import shutil
                    shutil.rmtree(local_path)
                    logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è½½: {local_path}")
                except Exception as e:
                    logger.error(f"æ¸…ç†å¤±è´¥: {e}")
    
    def update_config_file(self, config_path: Path):
        """æ›´æ–°é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ æœ¬åœ°æ¨¡å‹è·¯å¾„"""
        logger.info(f"ğŸ“ æ›´æ–°é…ç½®æ–‡ä»¶: {config_path}")
        
        try:
            # åŠ è½½ç°æœ‰é…ç½®
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æ·»åŠ æœ¬åœ°æ¨¡å‹é…ç½®
            if 'local_models' not in config:
                config['local_models'] = {}
            
            config['local_models']['enabled'] = True
            config['local_models']['base_path'] = str(self.models_dir)
            config['local_models']['models'] = {}
            
            # ä¸ºæ¯ä¸ªå·²ä¸‹è½½çš„æ¨¡å‹æ·»åŠ æœ¬åœ°è·¯å¾„é…ç½®
            for model_name, model_config in self.model_configs.items():
                if self.is_model_downloaded(model_name):
                    local_path = self.get_local_model_path(model_name)
                    config['local_models']['models'][model_name] = {
                        'local_path': str(local_path),
                        'model_type': model_config['type'],
                        'hidden_size': model_config['hidden_size']
                    }
            
            # ä¿å­˜æ›´æ–°åçš„é…ç½®
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
            
            logger.info("âœ… é…ç½®æ–‡ä»¶æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°é…ç½®æ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¸‹è½½å®éªŒä¸€æ‰€éœ€çš„é¢„è®­ç»ƒæ¨¡å‹åˆ°æœ¬åœ°')
    parser.add_argument('--models', nargs='+', help='æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹åç§°')
    parser.add_argument('--all', action='store_true', help='ä¸‹è½½æ‰€æœ‰å®éªŒæ‰€éœ€çš„æ¨¡å‹')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰')
    parser.add_argument('--clean', action='store_true', help='æ¸…ç†å¤±è´¥çš„ä¸‹è½½')
    parser.add_argument('--verify', action='store_true', help='éªŒè¯å·²ä¸‹è½½æ¨¡å‹çš„å®Œæ•´æ€§')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹')
    parser.add_argument('--update-config', action='store_true', help='æ›´æ–°é…ç½®æ–‡ä»¶')
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
    experiment_root = Path(__file__).parent.parent
    manager = LocalModelManager(experiment_root)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    (experiment_root / 'outputs' / 'logs').mkdir(parents=True, exist_ok=True)
    
    try:
        if args.clean:
            manager.clean_failed_downloads()
        
        elif args.list:
            downloaded = manager.list_downloaded_models()
            print("\nğŸ“‹ å·²ä¸‹è½½çš„æ¨¡å‹:")
            for local_name, info in downloaded.items():
                print(f"  â€¢ {info['hf_name']} â†’ {info['local_path']}")
                print(f"    ç±»å‹: {info['model_type']}, ä¸‹è½½æ—¶é—´: {info['download_time']}")
        
        elif args.verify:
            logger.info("ğŸ” éªŒè¯å·²ä¸‹è½½æ¨¡å‹çš„å®Œæ•´æ€§...")
            downloaded = manager.list_downloaded_models()
            for local_name, info in downloaded.items():
                local_path = Path(info['local_path'])
                if manager._verify_model_integrity(local_path, info['model_type']):
                    logger.info(f"âœ… {info['hf_name']} éªŒè¯é€šè¿‡")
                else:
                    logger.error(f"âŒ {info['hf_name']} éªŒè¯å¤±è´¥")
        
        elif args.all:
            # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
            results = manager.download_all_required_models(args.force)
            
            # æ›´æ–°é…ç½®æ–‡ä»¶
            if args.update_config or any(results.values()):
                config_path = experiment_root / 'config' / 'model_config.yaml'
                manager.update_config_file(config_path)
        
        elif args.models:
            # ä¸‹è½½æŒ‡å®šæ¨¡å‹
            results = {}
            for model_name in args.models:
                success = manager.download_model(model_name, args.force)
                results[model_name] = success
            
            manager._print_download_summary(results)
            
            # æ›´æ–°é…ç½®æ–‡ä»¶
            if args.update_config:
                config_path = experiment_root / 'config' / 'model_config.yaml'
                manager.update_config_file(config_path)
        
        elif args.update_config:
            # ä»…æ›´æ–°é…ç½®æ–‡ä»¶
            config_path = experiment_root / 'config' / 'model_config.yaml'
            manager.update_config_file(config_path)
        
        else:
            parser.print_help()
    
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        raise


if __name__ == "__main__":
    main()